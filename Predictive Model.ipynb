{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c93209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.60000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Load training data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Define a mapping from Dtest columns to Dtrain columns\n",
    "feature_mapping = {\n",
    "    'Verb': 'Var1',\n",
    "    'Noun': 'Var2',\n",
    "    'Prep': 'Var3',\n",
    "    'Prep_obj': 'Var4'\n",
    "}\n",
    "\n",
    "# Function to compute conditional probabilities using MLE and smoothing\n",
    "def compute_probabilities(data, class_label):\n",
    "    probabilities = {}\n",
    "    for feature in data.columns[:-1]:  # Exclude the class label column\n",
    "        feature_values = set(data[feature].unique())  # Unique values for the feature\n",
    "        probabilities[feature] = {}\n",
    "        for label in data[class_label].unique():\n",
    "            probabilities[feature][label] = {val: 0 for val in feature_values}  # Initialize with zeros\n",
    "            label_count = data[data[class_label] == label].shape[0]\n",
    "            for attribute in feature_values:\n",
    "                count_attribute_label = data[(data[feature] == attribute) & (data[class_label] == label)].shape[0]\n",
    "                probabilities[feature][label][attribute] = (count_attribute_label + 1) / (label_count + len(feature_values))\n",
    "    return probabilities\n",
    "\n",
    "# Train the model and save probabilities to a file\n",
    "model = compute_probabilities(train_data, 'Var5')\n",
    "np.save('model.npy', model)\n",
    "\n",
    "# Function to compute corpus cross entropy\n",
    "def compute_cross_entropy(instance, probabilities, label, feature_mapping):\n",
    "    entropy = 0\n",
    "    for test_feature, train_feature in feature_mapping.items():\n",
    "        attribute_value = instance[test_feature]\n",
    "        # Check if attribute value exists in the model, if not apply smoothing\n",
    "        if attribute_value not in probabilities[train_feature][label]:\n",
    "            probabilities[train_feature][label][attribute_value] = 1 / (len(probabilities[train_feature][label]) + 1)\n",
    "        entropy -= math.log2(probabilities[train_feature][label][attribute_value])\n",
    "    return entropy\n",
    "\n",
    "# Load model from file\n",
    "loaded_model = np.load('model.npy', allow_pickle=True).item()\n",
    "\n",
    "# Testing procedures\n",
    "accurate_predictions = 0\n",
    "for index, instance in test_data.iterrows():\n",
    "    entropies = {}\n",
    "    for label in ['V', 'N']:  # Class labels\n",
    "        entropies[label] = compute_cross_entropy(instance, loaded_model, label, feature_mapping)\n",
    "    assigned_label = min(entropies, key=entropies.get)\n",
    "    if assigned_label == instance['Class_label']:\n",
    "        accurate_predictions += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accurate_predictions / len(test_data)\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb289ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
